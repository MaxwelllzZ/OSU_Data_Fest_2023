---
title: "OSU_Datafest_2023"
author: "Sitong Zhang(zhang.10730)"
date: "4/1/2023"
output:
  html_document:
    code_folding: hide
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
# Load library
library(dplyr)
library(readr)
library(tidyverse)
library(dplyr)
library(usmap)
library(ggplot2)
library(ggthemes)

library(forecast)
library(lubridate)
```

```{r}
options(max.print = 10000) 
```
# R Markdown

upload dataset

```{r pressure, echo=FALSE}
Attorney <- read_csv("./data/data/attorneys.csv")

Attorney_time_entries <- read_csv("./data/data/attorneytimeentries.csv")

Categories <- read_csv("./data/data/categories.csv")

Clients <- read_csv("./data/data/clients.csv")

Question_posts <- read_csv("./data/data/questionposts.csv")

Questions <- read_csv("./data/data/questions.csv")

State_sites <- read_csv("./data/data/statesites.csv")

Subcategories <- read_csv("./data/data/subcategories.csv")
```


## Stats and Graph
```{r}
# Feature Engineering

# Replace 'NULL' with NA in 'Clients' dataframe
clients_na <- Clients %>% 
  mutate(across(where(is.character), ~na_if(., 'NULL')))

# Create a dataframe with complete cases from 'clients_na'
clients_complete <- clients_na[complete.cases(clients_na),]

# Combine 'clients_na' with 'questions' to get the 'Category' variable
clients_category <- clients_na %>% 
  left_join(Questions, by = c('ClientUno' = 'AskedByClientUno')) %>% 
  select(Id.x, StateAbbr.x, ClientUno, County, EthnicIdentity, Age, Gender, MaritalStatus, Veteran, Imprisoned, NumberInHousehold, AnnualIncome, AllowedIncome, CheckingBalance, SavingsBalance, InvestmentsBalance, CreatedUtc, Category)
```

### Bar graph taken ratio of each category
```{r}
# Analyze which type of Questions is most frequent
# Count the number of each type of question
question_counts <- Questions %>% 
  mutate(Taken = ifelse(TakenByAttorneyUno == 'NULL', 0, 1)) %>% 
  group_by(Category, Taken) %>% 
  summarize(n = n()) %>% 
  arrange(desc(Taken))

# Plotting the count of Questions by category
Questions %>% 
  mutate(Taken = ifelse(TakenByAttorneyUno == 'NULL', 0, 1)) %>% 
  group_by(Category, Taken) %>% 
  summarize(n = n()) %>% 
  ggplot(mapping = aes(x = reorder(Category, n), y = n, fill = factor(Taken))) +
  geom_col(position = 'dodge') +
  coord_flip() +
  theme_few()
```
### Graph of Demand by State for Family and Children Category 
```{r}
# Analyzing 'Family and Children' Category
# Subset for 'Family and Children'
clients_cf <- clients_category %>% 
  filter(Category == 'Family and Children')

# Analysis by State (Demand)
clients_cf_state_demand <- clients_cf %>% 
  group_by(StateAbbr.x) %>% 
  summarize(number = n())

# Plotting demand by state
ggplot(clients_cf_state_demand, aes(x = reorder(StateAbbr.x, number), y = number)) +
  geom_col(fill = 'blue') +
  coord_flip() +
  theme_few() +
  labs(title = "Demand by State for Family and Children Category", x = "State", y = "Number of Cases")
```
### Graph of Age Distribution in Family and Children Category
```{r}
# Analysis by Age
clients_cf_age_distribution <- clients_cf %>% 
  mutate(age = as.numeric(Age))

# Plotting age distribution
ggplot(clients_cf_age_distribution, aes(x = age)) +
  geom_histogram(binwidth = 5, fill = 'green') +
  theme_few() +
  labs(title = "Age Distribution in Family and Children Category", x = "Age", y = "Count")

```

### Graph of Ethnic Distribution in Family and Children Category
```{r}
# Analysis by Ethnic Identity
clients_cf_ethnic <- clients_cf %>% 
  group_by(EthnicIdentity) %>% 
  summarize(number = n()) %>% 
  filter(number > mean(number)) %>% 
  filter(EthnicIdentity %in% c('Caucasian', 'African American', 'Latino or Hispanic', "I'd rather not answer", 'Other', 'Asian', 'Native American or Alaska Native'))

# Plotting ethnic distribution
ggplot(clients_cf_ethnic, aes(x = reorder(EthnicIdentity, number), y = number)) +
  geom_col(fill = 'red') +
  coord_flip() +
  theme_few() +
  labs(title = "Ethnic Distribution in Family and Children Category", x = "Ethnic Identity", y = "Number")
```

### Pie graph of Subcategories
```{r}
# Feature Engineering for Subcategory
clients_subcategory <- clients_na %>% 
  left_join(Questions, by = c('ClientUno' = 'AskedByClientUno')) %>% 
  select(Id.x, StateAbbr.x, ClientUno, County, EthnicIdentity, Age, Gender, MaritalStatus, Veteran, Imprisoned, NumberInHousehold, AnnualIncome, AllowedIncome, CheckingBalance, SavingsBalance, InvestmentsBalance, CreatedUtc, Category, Subcategory)
# View(clients_subcategory)

# Filtering for 'Family and Children' Category
clients_cfsub <- clients_subcategory %>% 
  filter(Category == 'Family and Children')
# View(clients_cfsub)

# Viewing levels of Subcategory within the 'Family and Children' Category
# levels(factor(clients_cfsub$Subcategory))

# Creating a Pie Chart for Subcategory Distribution
# Summarizing the count of each Subcategory
pietu <- clients_cfsub %>% 
  group_by(Subcategory) %>% 
  summarize(n = n())

# Define the number of top categories to display
top_n_categories <- 20  

# Grouping all other categories under 'Other'
pietu_top <- pietu %>% 
  arrange(desc(n)) %>%
  mutate(Subcategory = ifelse(row_number() > top_n_categories, 'Other', Subcategory)) %>%
  group_by(Subcategory) %>%
  summarize(n = sum(n))

# Creating the Pie Chart
ggplot(pietu_top, aes(x = "", y = n, fill = Subcategory)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) +
  theme_void() +
  theme(legend.position = "right") +
  guides(fill = guide_legend(title = "Subcategory")) +
  scale_fill_viridis_d()
```


## Q1 Study the relationship between legalDDL and if the case is taken
```{r}
# Reload Data sets for the following steps
Attorney <- read_csv("./data/data/attorneys.csv")

Attorney_time_entries <- read_csv("./data/data/attorneytimeentries.csv")

Categories <- read_csv("./data/data/categories.csv")

Clients <- read_csv("./data/data/clients.csv")

Question_posts <- read_csv("./data/data/questionposts.csv")

Questions <- read_csv("./data/data/questions.csv")

State_sites <- read_csv("./data/data/statesites.csv")

Subcategories <- read_csv("./data/data/subcategories.csv")
```
Detect if there is a huge difference the question will be taken when there is a legal deadline.

```{r}
# Create a new dataset based on the Questions data set
Question_for_if_legal_ddl_matter <- Questions

# Add the Indicator_if_Lddl variable
Question_for_if_legal_ddl_matter$Indicator_if_Lddl <- ifelse(Question_for_if_legal_ddl_matter$LegalDeadline == "NULL", 0, 1)

# Add the Indicator_if_taken variable
Question_for_if_legal_ddl_matter$Indicator_if_taken <- ifelse(Question_for_if_legal_ddl_matter$TakenByAttorneyUno == "NULL", 0, 1)

model <- glm(Indicator_if_taken ~ Indicator_if_Lddl, data=Question_for_if_legal_ddl_matter, family=binomial())
summary(model)
```

```{r}
agg_data <- aggregate(Question_for_if_legal_ddl_matter$Indicator_if_taken, 
                      by=list(Question_for_if_legal_ddl_matter$Indicator_if_Lddl), 
                      FUN=mean)
names(agg_data) <- c("Indicator_if_Lddl", "Proportion_taken_by_attorney")
agg_data
```




```{r}
# Create a dataframe with predicted values for the model
pred_df <- data.frame(Indicator_if_Lddl = c(0, 1))
pred_df$predicted_prob <- predict(model, newdata = pred_df, type = "response")

# Create the plot
ggplot(data = Question_for_if_legal_ddl_matter, aes(x = Indicator_if_Lddl, y = Indicator_if_taken)) +
  geom_point() +
  geom_line(data = pred_df, aes(x = Indicator_if_Lddl, y = predicted_prob), color = "red") +
  xlab("Indicator_if_Lddl") +
  ylab("Indicator_if_taken") +
  ggtitle("Logistic Regression Model") +
  ylim(0.65, 0.75)
```


The output from the logistic regression model provides information on the relationship between the Indicator_if_taken variable (i.e., whether or not a case was taken by an attorney) and the Indicator_if_Lddl variable (i.e., whether or not there is a legal deadline associated with the case).

The first part of the output provides information on the goodness of fit of the model. The deviance residuals measure the difference between the predicted probabilities from the model and the actual outcomes, with lower values indicating better fit. In this case, the deviance residuals range from -1.5759 to 0.8359, with a median of 0.8258, suggesting that the model has a reasonably good fit.

The second part of the output provides information on the estimated coefficients for the model. The coefficient for the Indicator_if_Lddl variable is estimated to be -0.0289, with a standard error of 0.0118 and a z-value of -2.444. The negative sign of the coefficient indicates that the odds of a case being taken by an attorney decrease when there is a legal deadline associated with the case. The p-value associated with the coefficient is 0.0145, which is less than 0.05, indicating that the relationship between the Indicator_if_Lddl variable and the Indicator_if_taken variable is statistically significant.

The output also provides information on the null deviance, residual deviance, AIC, and number of iterations for the model. These values can be used to compare different models and evaluate their fit and complexity.


## Q2 Study the realtionship of the time attorney has joined ABA and number of cases taken

```{r}
# Aggregate the data by TakenByAttorneyUno and exclude rows with NULL
cases_by_agent <- Questions %>%
  filter(!is.null(TakenByAttorneyUno)) %>%
  group_by(TakenByAttorneyUno) %>%
  summarise(NumCases = n())
```


```{r}
# Aggregate the data by TakenByAttorneyUno and exclude rows with NULL
cases_by_attorney <- Questions %>%
  filter(!is.null(TakenByAttorneyUno)) %>%
  group_by(TakenByAttorneyUno) %>%
  summarise(NumCases = n())

# Full join the aggregated data with Attorney data frame on AttorneyUno
attorney_cases_and_join_date <- full_join(cases_by_attorney, Attorney, by = c("TakenByAttorneyUno" = "AttorneyUno"))

# Clean Data
attorney_cases_and_join_date <- subset(attorney_cases_and_join_date, TakenByAttorneyUno != "NULL")

# Replace NA values in NumCases with 0
attorney_cases_and_join_date$NumCases[is.na(attorney_cases_and_join_date$NumCases)] <- 0

# View the updated data frame
print(attorney_cases_and_join_date)

```


```{r}
# Filter out rows with NULL in TakenByAttorneyUno
filtered_attorney_cases_and_join_date <- attorney_cases_and_join_date %>%
  filter(!is.null(TakenByAttorneyUno))

# Convert CreatedUtc to Date format (ignoring the time)
attorney_cases_and_join_date$CreatedUtc <- as.Date(attorney_cases_and_join_date$CreatedUtc)

# Define the max day
max_day <- as.Date("2022-01-24")

# Calculate the difference between the max day and each CreatedUtc value
attorney_cases_and_join_date$DaysSince_CreatedUtc_Day <- as.numeric(max_day - attorney_cases_and_join_date$CreatedUtc)

# Run linear regression using NumCases as the dependent variable and DaysSince_CreatedUtc_Day as the independent variable
regression_model <- lm(NumCases ~ DaysSince_CreatedUtc_Day, data = attorney_cases_and_join_date)

# Print the regression model summary
summary(regression_model)
```


```{r}
# Create the plot-General
ggplot(data = attorney_cases_and_join_date, aes(x = DaysSince_CreatedUtc_Day, y = NumCases)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("DaysSince_CreatedUtc_Day") +
  ylab("NumCases") +
  ggtitle("Linear Regression Model") +
  ylim(0, max(attorney_cases_and_join_date$NumCases, na.rm = TRUE))
```



```{r}
# Create the plot-Closer look(95%CI) Theoretical Function
# Fit linear regression model
regression_model <- lm(NumCases ~ DaysSince_CreatedUtc_Day, data = attorney_cases_and_join_date)

# Predict values for 95% interval
predictions <- predict(regression_model, interval = "confidence")

# Calculate y-axis limits
y_upper <- max(predictions[, "upr"], na.rm = TRUE)
y_lower <- min(predictions[, "lwr"], na.rm = TRUE)
c(y_lower ,y_upper)

# Create the plot
ggplot(data = attorney_cases_and_join_date, aes(x = DaysSince_CreatedUtc_Day, y = NumCases)) +
  geom_point(color = "steelblue", size = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "darkred", linetype = "solid", size = 1.2) +
  geom_ribbon(aes(ymin = predictions[, "lwr"], ymax = predictions[, "upr"]),
              alpha = 0.2, fill = "lightblue") +
  scale_x_continuous("DaysSince_CreatedUtc_Day", expand = c(0, 0), breaks = seq(0, max(attorney_cases_and_join_date$DaysSince_CreatedUtc_Day), by = 10)) +
  scale_y_continuous("NumCases", limits = c(y_lower, y_upper), expand = c(0, 0), breaks = seq(y_lower, y_upper, by = 10)) +
  ggtitle("Linear Regression Model") +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(size = 18, hjust = 0.5),
        axis.title.x = element_text(size = 16),
        axis.title.y = element_text(size = 16),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_line(color = "grey92", size = 0.5))
```

```{r}
# Create the plot-Closer look(95%CI) Sample Data
# Calculate 95% confidence interval for NumCases
confidence_interval <- t.test(attorney_cases_and_join_date$NumCases, conf.level = 0.95)$conf.int

# Create the plot
ggplot(data = attorney_cases_and_join_date, aes(x = DaysSince_CreatedUtc_Day, y = NumCases)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("DaysSince_CreatedUtc_Day") +
  ylab("NumCases") +
  ggtitle("Linear Regression Model") +
  ylim(confidence_interval[1], confidence_interval[2])
```

```{r}
# mean join day
mean_join_day<- mean(attorney_cases_and_join_date$DaysSince_CreatedUtc_Day, na.rm = TRUE)
mean_join_year <- mean_join_day/365 ; mean_join_year

average_taken_case <- 1.623553 + 0.008754 * mean_join_day; average_taken_case
```

From here, we know that the time an attorney joins ABA is statistically significant. It means it is necessarily associate with the number of cases they helped.

### Q2 Advanced analysis of the ratio of the cases of each categories being taken

```{r}
# Calculate rate of cases being taken by Category
category_rate <- aggregate(Questions$TakenByAttorneyUno, by = list(Questions$Category), FUN = function(x) sum(x != "NULL")/length(x) * 100)

# Rename columns
names(category_rate) <- c("Category", "Rate")

# Print the result
category_rate
```

Calculate the taken rate of each category and total taken rate expressed as a percentage:

```{r}
# Calculate taken rate by category
taken_rate_by_category <- Question_for_if_legal_ddl_matter %>%
  group_by(Category) %>%
  summarize(TotalCases = n(),
            TakenCases = sum(Indicator_if_taken),
            TakenRate = (TakenCases / TotalCases) * 100)

# Calculate the overall taken rate
overall_taken_rate <- Question_for_if_legal_ddl_matter %>%
  summarize(TotalCases = n(),
            TakenCases = sum(Indicator_if_taken),
            TakenRate = (TakenCases / TotalCases) * 100) %>%
  mutate(Category = "Total")

# Combine the overall taken rate with the taken rate by category
combined_result <- rbind(taken_rate_by_category, overall_taken_rate)

# Print the combined result
print(combined_result)

```

```{r}
# Perform Chi-Square to see if means are different between categories

# Create a contingency table of Category and Indicator_if_taken
contingency_table <- table(Question_for_if_legal_ddl_matter$Category, Question_for_if_legal_ddl_matter$Indicator_if_taken)

# Perform the Chi-square test
chi_square_test <- chisq.test(contingency_table)

# Print the result
print(chi_square_test)
```

The output you provided shows the results of the Pearson's Chi-squared test on the contingency table of Category and Indicator_if_taken. Here's how to interpret the results:

X-squared: The Chi-square statistic value is 1752.3. This value is used to determine the significance of the test.
df: Degrees of freedom for this test is 9. It is calculated as (number of categories - 1) x (number of levels of Indicator_if_taken - 1) = (10 - 1) x (2 - 1) = 9.
p-value: The p-value is less than 2.2e-16, which is extremely small and much lower than the common significance level of 0.05.
Since the p-value is less than 0.05, you can reject the null hypothesis and conclude that there is a statistically significant difference in the taken rates between the categories.

## Combining 1 and 2, I want to explore whether categories with a Taken rate less than 60 and 75 are influenced by the existence of a legal ddl (whether a legal ddl is an essential element for the Taken rate).
### Combining 1 and 2, I want to explore whether categories with a Taken rate less than 60 are influenced by the existence of a legal ddl (whether a legal ddl is an essential element for the Taken rate).

```{r}
# Filter the categories with a taken rate below 60%
categories_below_60 <- taken_rate_by_category %>%
  filter(TakenRate < 60) %>%
  pull(Category)

# Filter the dataset to only include categories with a taken rate smaller than 60%
filtered_data <- Question_for_if_legal_ddl_matter %>%
  filter(Category %in% categories_below_60)

# Fit logistic regression model with interaction term
logit_model_interaction <- glm(Indicator_if_taken ~ Category * Indicator_if_Lddl,
                               data = filtered_data,
                               family = binomial(link = "logit"))

# Display the model summary for the model with interaction term
summary(logit_model_interaction)

# Perform logistic regression without interaction term
logit_model_no_interaction <- glm(Indicator_if_taken ~ Category,
                                  data = filtered_data,
                                  family = binomial(link = "logit"))

# Display the model summary for the model without interaction term
summary(logit_model_no_interaction)

```
The taken rate of Individual Rights when there is a legal deadline is exp{0.41001}. There isn't statistically significant difference between groups if legal ddl exist.
The taken rate of Juvenile when there is a legal deadline is exp{0.43474}. Because Junevile cases are rare, statistics are not statistically significant.


### Combining 1 and 2, I want to explore whether categories with a Taken rate greater than 75 are influenced by the existence of a legal ddl (whether a legal ddl is an essential element for the Taken rate).

```{r}
# Filter the categories with a taken rate above 75%
categories_above_75 <- taken_rate_by_category %>%
  filter(TakenRate > 75) %>%
  pull(Category)

categories_above_75


# Filter the dataset to only include categories with a taken rate greater than 75%
filtered_data <- Question_for_if_legal_ddl_matter %>%
  filter(Category %in% categories_above_75)

# Fit logistic regression model with interaction term
logit_model_interaction <- glm(Indicator_if_taken ~ Category * Indicator_if_Lddl,
                               data = filtered_data,
                               family = binomial(link = "logit"))

# Display the model summary for the model with interaction term
summary(logit_model_interaction)

# Perform logistic regression without interaction term
logit_model_no_interaction <- glm(Indicator_if_taken ~ Category,
                                  data = filtered_data,
                                  family = binomial(link = "logit"))

# Display the model summary for the model without interaction term
summary(logit_model_no_interaction)
```
Interpreting the coefficient in with interaction model will give us "Consumer Financial Questions" is exp{1.05411}, "Housing and Homelessness" exp{1.05411+0.12624}. It tells us that "Consumer Financial Question" that has no legal ddl has statistically significant difference with "Housing and Homelessness", "Consumer Financial Question" that has legal ddl, and "Housing and Homelessness" with legal ddl.

Interpreting the coefficient in no interaction model just give us the overall taken rate of "Consumer Financial Questions" and "Housing and Homelessness". And only intercept is statistically significant.


## Anlysis for Family and Children category only
```{r}
# Filter the dataset to only include the "Family and Children" category
filtered_data <- Question_for_if_legal_ddl_matter %>%
  filter(Category == "Family and Children")

# Perform logistic regression with Indicator_if_Lddl as the only predictor
logit_model_FAC <- glm(Indicator_if_taken ~ Indicator_if_Lddl,
                   data = filtered_data,
                   family = binomial(link = "logit"))

# Display the model summary
summary(logit_model_FAC)
```
There is no statistically significant within Family and Children between the No_Legal_ddl group and With_Legal_ddl group.

### TS Family and Children
分类 Famaly and Children, Indicator_if_taken = 0 and Indicator_if_taken = 1.
```{r}
# Filter the dataset for the "Family and Children" category and Indicator_if_taken
family_children_data_taken <- Question_for_if_legal_ddl_matter %>%
  filter(Category == "Family and Children" & Indicator_if_taken == 1)

family_children_data_not_taken <- Question_for_if_legal_ddl_matter %>%
  filter(Category == "Family and Children" & Indicator_if_taken == 0)


family_children_monthly_taken <- family_children_data_taken %>%
  mutate(Month = floor_date(AskedOnUtc, "month")) %>%
  group_by(Month) %>%
  summarize(NumQuestions = n()) %>%
  ungroup()

family_children_monthly_not_taken <- family_children_data_not_taken %>%
  mutate(Month = floor_date(AskedOnUtc, "month")) %>%
  group_by(Month) %>%
  summarize(NumQuestions = n()) %>%
  ungroup()


family_children_ts_taken <- ts(family_children_monthly_taken$NumQuestions,
                               start = c(year(min(family_children_monthly_taken$Month)), month(min(family_children_monthly_taken$Month))),
                               frequency = 12)

family_children_ts_not_taken <- ts(family_children_monthly_not_taken$NumQuestions,
                                   start = c(year(min(family_children_monthly_not_taken$Month)), month(min(family_children_monthly_not_taken$Month))),
                                   frequency = 12)

model_taken <- auto.arima(family_children_ts_taken)
summary(model_taken)

model_not_taken <- auto.arima(family_children_ts_not_taken)
summary(model_not_taken)

```

Combining the two sets of data mentioned above, continue with time series modeling.
```{r}
# Combine the taken and not taken time series
family_children_ts_combined <- family_children_ts_taken + family_children_ts_not_taken

# Fit a combined time series model
combined_model <- auto.arima(family_children_ts_combined, seasonal = TRUE, stepwise = FALSE, approximation = FALSE)

# Display the model summary
summary(combined_model)
```
Since it is ar1 and sar1, it has trend and seasonality. It is influenced by the immediate past value and the value 12 months ago(n=12). Since it is ARIMA(1,1,0)(1,0,0)[12], in the non seasonal part, it shows differencing is 1, there is a trend. Meanwhile, in the seasonal part, it shows differencing is 0, so the trend is seasonally contant throughout years.

```{r}
# Number of periods to forecast
n_periods <- 12

# Forecast taken questions
forecast_taken <- forecast(model_taken, h = n_periods)
# Forecast not taken questions
forecast_not_taken <- forecast(model_not_taken, h = n_periods)
# Forecast combined questions
forecast_combined <- forecast(combined_model, h = n_periods)


# Create the plots
par(mfrow = c(3, 1))

# Plot taken questions
plot(forecast_taken, main = "Forecast of Taken Questions", ylab = "Number of Questions", xlab = "Time")
# Plot not taken questions
plot(forecast_not_taken, main = "Forecast of Not Taken Questions", ylab = "Number of Questions", xlab = "Time")
# Plot combined questions
plot(forecast_combined, main = "Forecast of Combined Questions", ylab = "Number of Questions", xlab = "Time")

# Reset the plotting parameters
par(mfrow = c(1, 1))

```